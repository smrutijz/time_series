{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, RepeatVector, Dense, TimeDistributed\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'.\\data\\stock_prices_sample.csv')\n",
    "df = df[df.TICKER != 'GEF']\n",
    "df = df[df.TYPE != 'Intraday']\n",
    "df.reset_index(drop = True, inplace =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SPLIT=700\n",
    "\n",
    "LOOK_BACK_WINDOW = 180\n",
    "NUM_OF_FUTURE_PREDICTION = 90\n",
    "\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 100\n",
    "EVALUATION_INTERVAL = 20\n",
    "VALIDATION_INTERVAL = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features_considered = [\"OPEN\", \"HIGH\", \"LOW\", \"CLOSE\"]\n",
    "input_features = df[input_features_considered]\n",
    "input_data = input_features.values\n",
    "# normalize the dataset\n",
    "input_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = input_scaler.fit_transform(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_features_considered = [\"OPEN\", \"CLOSE\"]\n",
    "output_features = df[output_features_considered]\n",
    "target_data = output_features.values\n",
    "# normalize the dataset\n",
    "output_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "target = output_scaler.fit_transform(target_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_data(dataset, target, start_index, end_index, history_size, target_size):\n",
    "    data = []\n",
    "    labels = []\n",
    "    start_index = start_index + history_size\n",
    "    if end_index is None:\n",
    "        end_index = len(dataset) - target_size\n",
    "    for i in range(start_index, end_index):\n",
    "        indices = range(i-history_size, i)\n",
    "        data.append(dataset[indices])\n",
    "        labels.append(target[i:i+target_size])\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train: (520, 180, 4)\n",
      "shape of y_train: (520, 90, 2)\n",
      "shape of x_val: (25, 180, 4)\n",
      "shape of y_val: (25, 90, 2)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = multivariate_data(dataset=dataset\n",
    "                                     , target=target\n",
    "                                     , start_index=0\n",
    "                                     , end_index=TRAIN_SPLIT\n",
    "                                     , history_size=LOOK_BACK_WINDOW\n",
    "                                     , target_size=NUM_OF_FUTURE_PREDICTION)\n",
    "\n",
    "x_val, y_val = multivariate_data(dataset=dataset\n",
    "                                 , target=target\n",
    "                                 , start_index=TRAIN_SPLIT\n",
    "                                 , end_index=None\n",
    "                                 , history_size=LOOK_BACK_WINDOW\n",
    "                                 , target_size=NUM_OF_FUTURE_PREDICTION)\n",
    "\n",
    "print(\"shape of x_train:\", x_train.shape)\n",
    "print(\"shape of y_train:\", y_train.shape)\n",
    "print(\"shape of x_val:\", x_val.shape)\n",
    "print(\"shape of y_val:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN LSTM Encoder & Decoder Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\smrut\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(200, activation='relu', input_shape=x_train.shape[-2:]))\n",
    "model.add(RepeatVector(y_train.shape[1]))\n",
    "model.add(LSTM(200, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(100, activation='relu')))\n",
    "model.add(TimeDistributed(Dense(y_train.shape[2])))\n",
    "\n",
    "model.compile(optimizer=RMSprop(clipvalue=1.0), loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Trining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\smrut\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 520 samples, validate on 25 samples\n",
      "Epoch 1/100\n",
      "520/520 [==============================] - 16s 30ms/sample - loss: 0.0238 - val_loss: 0.0433\n",
      "Epoch 2/100\n",
      "520/520 [==============================] - 14s 28ms/sample - loss: 0.0097 - val_loss: 0.0329\n",
      "Epoch 3/100\n",
      "520/520 [==============================] - 14s 28ms/sample - loss: 0.0106 - val_loss: 0.0175\n",
      "Epoch 4/100\n",
      "520/520 [==============================] - 14s 27ms/sample - loss: 0.0104 - val_loss: 0.0595\n",
      "Epoch 5/100\n",
      "520/520 [==============================] - 14s 27ms/sample - loss: 0.0089 - val_loss: 0.0378\n",
      "Epoch 6/100\n",
      "520/520 [==============================] - 14s 27ms/sample - loss: 0.0118 - val_loss: 0.0443\n",
      "Epoch 7/100\n",
      "520/520 [==============================] - 14s 27ms/sample - loss: 0.0087 - val_loss: 0.0595\n",
      "Epoch 8/100\n",
      "520/520 [==============================] - 14s 27ms/sample - loss: 0.0084 - val_loss: 0.0228\n",
      "Epoch 9/100\n",
      "520/520 [==============================] - 13s 25ms/sample - loss: 0.0084 - val_loss: 0.0229\n",
      "Epoch 10/100\n",
      "520/520 [==============================] - 14s 27ms/sample - loss: 0.0086 - val_loss: 0.0252\n",
      "Epoch 11/100\n",
      "520/520 [==============================] - 14s 27ms/sample - loss: 0.0089 - val_loss: 0.0310\n",
      "Epoch 12/100\n",
      "520/520 [==============================] - 14s 27ms/sample - loss: 0.0079 - val_loss: 0.0795\n",
      "Epoch 13/100\n",
      "520/520 [==============================] - 14s 27ms/sample - loss: 0.0077 - val_loss: 0.0293\n",
      "Epoch 14/100\n",
      "520/520 [==============================] - 14s 27ms/sample - loss: 0.0078 - val_loss: 0.0497\n",
      "Epoch 15/100\n",
      "520/520 [==============================] - 14s 27ms/sample - loss: 0.0081 - val_loss: 0.0251\n",
      "Epoch 16/100\n",
      "520/520 [==============================] - 14s 28ms/sample - loss: 0.0076 - val_loss: 0.0325\n",
      "Epoch 17/100\n",
      "520/520 [==============================] - 13s 26ms/sample - loss: 0.0073 - val_loss: 0.0605\n",
      "Epoch 18/100\n",
      "520/520 [==============================] - 16s 30ms/sample - loss: 0.0074 - val_loss: 0.0195\n",
      "Epoch 19/100\n",
      "520/520 [==============================] - 14s 28ms/sample - loss: 0.0071 - val_loss: 0.0399\n",
      "Epoch 20/100\n",
      "520/520 [==============================] - 15s 28ms/sample - loss: 0.0077 - val_loss: 0.0342\n",
      "Epoch 21/100\n",
      "520/520 [==============================] - 14s 28ms/sample - loss: 0.0070 - val_loss: 0.0405\n",
      "Epoch 22/100\n",
      "520/520 [==============================] - 14s 28ms/sample - loss: 0.0073 - val_loss: 0.0465\n",
      "Epoch 23/100\n",
      "520/520 [==============================] - 14s 28ms/sample - loss: 0.0075 - val_loss: 0.0851\n",
      "Epoch 24/100\n",
      "520/520 [==============================] - 15s 28ms/sample - loss: 0.0074 - val_loss: 0.0296\n",
      "Epoch 25/100\n",
      "520/520 [==============================] - 15s 28ms/sample - loss: 0.0066 - val_loss: 0.0189\n",
      "Epoch 26/100\n",
      "520/520 [==============================] - 15s 28ms/sample - loss: 11.4201 - val_loss: 0.0469\n",
      "Epoch 27/100\n",
      "520/520 [==============================] - 15s 30ms/sample - loss: 0.0061 - val_loss: 0.0295\n",
      "Epoch 28/100\n",
      "520/520 [==============================] - 14s 26ms/sample - loss: 0.0062 - val_loss: 0.0252\n",
      "Epoch 29/100\n",
      "520/520 [==============================] - 15s 28ms/sample - loss: 0.0057 - val_loss: 0.0458\n",
      "Epoch 30/100\n",
      "520/520 [==============================] - 15s 28ms/sample - loss: 739.2782 - val_loss: 0.0310\n",
      "Epoch 31/100\n",
      "520/520 [==============================] - 15s 28ms/sample - loss: 576782747364.4369 - val_loss: 0.0321\n",
      "Epoch 32/100\n",
      "520/520 [==============================] - 15s 28ms/sample - loss: 0.0063 - val_loss: 0.0407\n",
      "Epoch 33/100\n",
      "520/520 [==============================] - 15s 29ms/sample - loss: 0.0060 - val_loss: 0.0360\n",
      "Epoch 34/100\n",
      "520/520 [==============================] - 15s 29ms/sample - loss: 0.0056 - val_loss: 0.0393\n",
      "Epoch 35/100\n",
      "520/520 [==============================] - 15s 29ms/sample - loss: 1343056624996541.0000 - val_loss: 0.0449\n",
      "Epoch 36/100\n",
      "520/520 [==============================] - 15s 29ms/sample - loss: 0.0061 - val_loss: 0.0412\n",
      "Epoch 37/100\n",
      "520/520 [==============================] - 15s 29ms/sample - loss: 0.0059 - val_loss: 0.0321\n",
      "Epoch 38/100\n",
      "520/520 [==============================] - 15s 29ms/sample - loss: 0.0060 - val_loss: 0.0433\n",
      "Epoch 39/100\n",
      "520/520 [==============================] - 15s 29ms/sample - loss: 0.0059 - val_loss: 0.0384\n",
      "Epoch 40/100\n",
      "520/520 [==============================] - 16s 30ms/sample - loss: 356870728607018059552522240.0000 - val_loss: 9223248896.0000\n",
      "Epoch 41/100\n",
      "520/520 [==============================] - 15s 30ms/sample - loss: 2951219786.2116 - val_loss: 0.0396\n",
      "Epoch 42/100\n",
      "520/520 [==============================] - 16s 30ms/sample - loss: 0.0076 - val_loss: 0.0358\n",
      "Epoch 43/100\n",
      "520/520 [==============================] - 15s 28ms/sample - loss: 0.0070 - val_loss: 0.0303\n",
      "Epoch 44/100\n",
      "520/520 [==============================] - 14s 27ms/sample - loss: 0.0067 - val_loss: 0.0411\n",
      "Epoch 45/100\n",
      "520/520 [==============================] - 14s 28ms/sample - loss: 0.0063 - val_loss: 0.0658\n",
      "Epoch 46/100\n",
      "520/520 [==============================] - 15s 28ms/sample - loss: 0.0064 - val_loss: 0.0346\n",
      "Epoch 47/100\n",
      "520/520 [==============================] - 15s 29ms/sample - loss: 0.0065 - val_loss: 0.0676\n",
      "Epoch 48/100\n",
      "520/520 [==============================] - 15s 29ms/sample - loss: 0.0067 - val_loss: 0.0280\n",
      "Epoch 49/100\n",
      "520/520 [==============================] - 15s 29ms/sample - loss: 0.0072 - val_loss: 0.0145\n",
      "Epoch 50/100\n",
      "520/520 [==============================] - 15s 29ms/sample - loss: 0.0071 - val_loss: 0.0698\n",
      "Epoch 51/100\n",
      "520/520 [==============================] - 16s 30ms/sample - loss: 0.0063 - val_loss: 0.0303\n",
      "Epoch 52/100\n",
      "520/520 [==============================] - 15s 29ms/sample - loss: 0.0069 - val_loss: 0.0671\n",
      "Epoch 53/100\n",
      "520/520 [==============================] - 20s 39ms/sample - loss: 0.0061 - val_loss: 0.0202\n",
      "Epoch 54/100\n",
      "520/520 [==============================] - 17s 33ms/sample - loss: 0.0061 - val_loss: 0.0281\n",
      "Epoch 55/100\n",
      "520/520 [==============================] - 17s 32ms/sample - loss: 0.0083 - val_loss: 0.0437\n",
      "Epoch 56/100\n",
      "520/520 [==============================] - 19s 37ms/sample - loss: 30261986954687329622556672.0000 - val_loss: 0.0360\n",
      "Epoch 57/100\n",
      "520/520 [==============================] - 18s 34ms/sample - loss: 0.0057 - val_loss: 0.0395\n",
      "Epoch 58/100\n",
      "520/520 [==============================] - 18s 34ms/sample - loss: 0.0053 - val_loss: 0.0342\n",
      "Epoch 59/100\n",
      "520/520 [==============================] - 17s 33ms/sample - loss: 0.0051 - val_loss: 0.0154\n",
      "Epoch 60/100\n",
      "520/520 [==============================] - 18s 34ms/sample - loss: 155505301.6667 - val_loss: 0.0531\n",
      "Epoch 61/100\n",
      "520/520 [==============================] - 18s 34ms/sample - loss: 0.0062 - val_loss: 0.0452\n",
      "Epoch 62/100\n",
      "520/520 [==============================] - 18s 34ms/sample - loss: 0.0056 - val_loss: 0.0465\n",
      "Epoch 63/100\n",
      "520/520 [==============================] - 18s 34ms/sample - loss: 0.0055 - val_loss: 0.0334\n",
      "Epoch 64/100\n",
      "520/520 [==============================] - 17s 33ms/sample - loss: 0.0053 - val_loss: 0.0559\n",
      "Epoch 65/100\n",
      "520/520 [==============================] - 18s 34ms/sample - loss: 0.0052 - val_loss: 0.0815\n",
      "Epoch 66/100\n",
      "520/520 [==============================] - 19s 37ms/sample - loss: 2244455551761927.7500 - val_loss: 0.0401\n",
      "Epoch 67/100\n",
      "520/520 [==============================] - 19s 37ms/sample - loss: 0.0050 - val_loss: 0.0373\n",
      "Epoch 68/100\n",
      "520/520 [==============================] - 18s 35ms/sample - loss: 0.0046 - val_loss: 0.0587\n",
      "Epoch 69/100\n",
      "520/520 [==============================] - 18s 35ms/sample - loss: 0.0042 - val_loss: 0.0702\n",
      "Epoch 70/100\n",
      "520/520 [==============================] - 20s 38ms/sample - loss: 22403.7904 - val_loss: 0.0330\n",
      "Epoch 71/100\n",
      "520/520 [==============================] - 19s 37ms/sample - loss: 0.0054 - val_loss: 0.0270\n",
      "Epoch 72/100\n",
      "520/520 [==============================] - 19s 36ms/sample - loss: 0.0052 - val_loss: 0.0521\n",
      "Epoch 73/100\n",
      "520/520 [==============================] - 18s 35ms/sample - loss: 0.0053 - val_loss: 0.0495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100\n",
      "520/520 [==============================] - 19s 36ms/sample - loss: 0.0050 - val_loss: 0.0146\n",
      "Epoch 75/100\n",
      "520/520 [==============================] - 18s 35ms/sample - loss: 0.0075 - val_loss: 0.0321\n",
      "Epoch 76/100\n",
      "520/520 [==============================] - 19s 36ms/sample - loss: 0.0053 - val_loss: 0.0363\n",
      "Epoch 77/100\n",
      "520/520 [==============================] - 20s 38ms/sample - loss: 0.0050 - val_loss: 0.0342\n",
      "Epoch 78/100\n",
      "520/520 [==============================] - 19s 36ms/sample - loss: 0.0049 - val_loss: 0.0768\n",
      "Epoch 79/100\n",
      "520/520 [==============================] - 19s 36ms/sample - loss: 0.0053 - val_loss: 0.0424\n",
      "Epoch 80/100\n",
      "520/520 [==============================] - 19s 36ms/sample - loss: 0.0045 - val_loss: 0.0877\n",
      "Epoch 81/100\n",
      "520/520 [==============================] - 19s 37ms/sample - loss: 0.0052 - val_loss: 0.0578\n",
      "Epoch 82/100\n",
      "520/520 [==============================] - 20s 39ms/sample - loss: 0.0052 - val_loss: 0.0451\n",
      "Epoch 83/100\n",
      "520/520 [==============================] - 19s 37ms/sample - loss: 0.0049 - val_loss: 0.0520\n",
      "Epoch 84/100\n",
      "520/520 [==============================] - 20s 38ms/sample - loss: 0.0046 - val_loss: 0.0483\n",
      "Epoch 85/100\n",
      "520/520 [==============================] - 19s 37ms/sample - loss: 0.0042 - val_loss: 0.0289\n",
      "Epoch 86/100\n",
      "520/520 [==============================] - 22s 42ms/sample - loss: 0.0040 - val_loss: 0.0421\n",
      "Epoch 87/100\n",
      "520/520 [==============================] - 18s 35ms/sample - loss: 0.0047 - val_loss: 0.0460\n",
      "Epoch 88/100\n",
      "520/520 [==============================] - 19s 36ms/sample - loss: 0.0046 - val_loss: 0.0612\n",
      "Epoch 89/100\n",
      "520/520 [==============================] - 19s 36ms/sample - loss: 0.0034 - val_loss: 0.0313\n",
      "Epoch 90/100\n",
      "520/520 [==============================] - 19s 36ms/sample - loss: 0.0040 - val_loss: 0.0414\n",
      "Epoch 91/100\n",
      "520/520 [==============================] - 19s 36ms/sample - loss: 0.0038 - val_loss: 0.0390\n",
      "Epoch 92/100\n",
      "520/520 [==============================] - 20s 38ms/sample - loss: 0.0037 - val_loss: 0.0307\n",
      "Epoch 93/100\n",
      "520/520 [==============================] - 19s 37ms/sample - loss: 0.0036 - val_loss: 0.0259\n",
      "Epoch 94/100\n",
      "520/520 [==============================] - 19s 37ms/sample - loss: 0.0038 - val_loss: 0.0283\n",
      "Epoch 95/100\n",
      "520/520 [==============================] - 20s 38ms/sample - loss: 0.0037 - val_loss: 0.0646\n",
      "Epoch 96/100\n",
      "520/520 [==============================] - 20s 39ms/sample - loss: 0.0035 - val_loss: 0.0755\n",
      "Epoch 97/100\n",
      "520/520 [==============================] - 20s 38ms/sample - loss: 0.0035 - val_loss: 0.0355\n",
      "Epoch 98/100\n",
      "520/520 [==============================] - 20s 38ms/sample - loss: nan - val_loss: nan\n",
      "Epoch 99/100\n",
      "520/520 [==============================] - 20s 38ms/sample - loss: nan - val_loss: nan\n",
      "Epoch 100/100\n",
      "520/520 [==============================] - 21s 40ms/sample - loss: nan - val_loss: nan\n"
     ]
    }
   ],
   "source": [
    "model_history = model.fit(x=x_train, y=y_train\n",
    "                          , epochs=EPOCHS\n",
    "                          , validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & CV Error (curve by epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_train_history(history, title):\n",
    "    loss = history.history['loss'][5:]\n",
    "    val_loss = history.history['val_loss'][5:]\n",
    "    epochs = range(len(loss))\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_train_history(model_history, 'Multi-Step Training and validation loss')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 200)               164000    \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 90, 200)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 90, 200)           320800    \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 90, 100)           20100     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 90, 2)             202       \n",
      "=================================================================\n",
      "Total params: 505,102\n",
      "Trainable params: 505,102\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_predict = dataset[-90:,:]\n",
    "data_predict = data_predict.reshape((1, data_predict.shape[0], data_predict.shape[1]))\n",
    "data_extrapolated = output_scaler.inverse_transform(model.predict(data_predict)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = (1,2)\n",
    "plt.figure(figsize=(17, 8))\n",
    "plt.subplot2grid(layout, (0,0))\n",
    "plt.plot(input_data[:,[0,3]], label='training data model')\n",
    "plt.axis([0, 995, 10, 25])\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title('Actual')\n",
    "plt.subplot2grid(layout, (0,1))\n",
    "plt.plot(data_extrapolated, label='testing data model')\n",
    "plt.title('Forecast')\n",
    "plt.axis([0, 995, 10, 25])\n",
    "plt.legend()\n",
    "plt.grid(True);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
