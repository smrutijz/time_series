{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'.\\data\\stock_prices_sample.csv')\n",
    "df = df[df.TICKER != 'GEF']\n",
    "df = df[df.TYPE != 'Intraday']\n",
    "df.reset_index(drop = True, inplace =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SPLIT=700\n",
    "\n",
    "features_considered = [\"CLOSE\"]\n",
    "LOOK_BACK = 90\n",
    "NUM_OF_FUTURE_PREDICTION = 60\n",
    "\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 30\n",
    "EVALUATION_INTERVAL = 20\n",
    "VALIDATION_INTERVAL = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[features_considered]\n",
    "data = features.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_data(dataset, target, start_index, end_index, history_size, target_size):\n",
    "    data = []\n",
    "    labels = []\n",
    "    start_index = start_index + history_size\n",
    "    if end_index is None:\n",
    "        end_index = len(dataset) - target_size\n",
    "    for i in range(start_index, end_index):\n",
    "        indices = range(i-history_size, i)\n",
    "        data.append(dataset[indices])\n",
    "        labels.append(target[i:i+target_size])\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train: (610, 90, 1)\n",
      "shape of y_train: (610, 60)\n",
      "shape of x_val: (145, 90, 1)\n",
      "shape of y_val: (145, 60)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = multivariate_data(dataset=dataset\n",
    "                                     , target=dataset[:, 0]\n",
    "                                     , start_index=0\n",
    "                                     , end_index=TRAIN_SPLIT\n",
    "                                     , history_size=LOOK_BACK\n",
    "                                     , target_size=NUM_OF_FUTURE_PREDICTION)\n",
    "\n",
    "x_val, y_val = multivariate_data(dataset=dataset\n",
    "                                 , target=dataset[:, 0]\n",
    "                                 , start_index=TRAIN_SPLIT\n",
    "                                 , end_index=None\n",
    "                                 , history_size=LOOK_BACK\n",
    "                                 , target_size=NUM_OF_FUTURE_PREDICTION)\n",
    "\n",
    "print(\"shape of x_train:\", x_train.shape)\n",
    "print(\"shape of y_train:\", y_train.shape)\n",
    "print(\"shape of x_val:\", x_val.shape)\n",
    "print(\"shape of y_val:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN LSTM Encoder & Decoder Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\smrut\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True, input_shape=x_train.shape[-2:]))\n",
    "model.add(LSTM(16, activation='relu'))\n",
    "model.add(Dense(NUM_OF_FUTURE_PREDICTION))\n",
    "\n",
    "model.compile(optimizer=RMSprop(clipvalue=1.0), loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Trining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n",
      "WARNING:tensorflow:From C:\\Users\\smrut\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 20 samples, validate on 145 samples\n",
      "Epoch 1/30\n",
      "20/20 [==============================] - 23s 1s/step - loss: 213.1363 - val_loss: 0.1806\n",
      "Epoch 2/30\n",
      "20/20 [==============================] - 22s 1s/step - loss: 0.1042 - val_loss: 0.1734\n",
      "Epoch 3/30\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0968 - val_loss: 0.1573\n",
      "Epoch 4/30\n",
      "20/20 [==============================] - 28s 1s/step - loss: 0.0818 - val_loss: 0.1320\n",
      "Epoch 5/30\n",
      "20/20 [==============================] - 24s 1s/step - loss: 0.0604 - val_loss: 0.0950\n",
      "Epoch 6/30\n",
      "20/20 [==============================] - 28s 1s/step - loss: 0.0360 - val_loss: 0.0663\n",
      "Epoch 7/30\n",
      "20/20 [==============================] - 31s 2s/step - loss: 0.0228 - val_loss: 0.0538\n",
      "Epoch 8/30\n",
      "20/20 [==============================] - 23s 1s/step - loss: 0.0151 - val_loss: 0.0454\n",
      "Epoch 9/30\n",
      "20/20 [==============================] - 24s 1s/step - loss: 0.0090 - val_loss: 0.0354\n",
      "Epoch 10/30\n",
      "20/20 [==============================] - 24s 1s/step - loss: 0.0093 - val_loss: 0.0386\n",
      "Epoch 11/30\n",
      "20/20 [==============================] - 25s 1s/step - loss: 0.0083 - val_loss: 0.0389\n",
      "Epoch 12/30\n",
      "20/20 [==============================] - 24s 1s/step - loss: 0.0078 - val_loss: 0.0390\n",
      "Epoch 13/30\n",
      "20/20 [==============================] - 11s 534ms/step - loss: 0.0075 - val_loss: 0.0392\n",
      "Epoch 14/30\n",
      "20/20 [==============================] - 7s 358ms/step - loss: 0.0073 - val_loss: 0.0394\n",
      "Epoch 15/30\n",
      "20/20 [==============================] - 7s 353ms/step - loss: 0.0071 - val_loss: 0.0397\n",
      "Epoch 16/30\n",
      "20/20 [==============================] - 8s 381ms/step - loss: 0.0069 - val_loss: 0.0398\n",
      "Epoch 17/30\n",
      "20/20 [==============================] - 8s 413ms/step - loss: 0.0068 - val_loss: 0.0400\n",
      "Epoch 18/30\n",
      "20/20 [==============================] - 7s 366ms/step - loss: 0.0066 - val_loss: 0.0399\n",
      "Epoch 19/30\n",
      "20/20 [==============================] - 9s 440ms/step - loss: 0.0065 - val_loss: 0.0402\n",
      "Epoch 20/30\n",
      "20/20 [==============================] - 7s 354ms/step - loss: 0.0064 - val_loss: 0.0406\n",
      "Epoch 21/30\n",
      "20/20 [==============================] - 7s 367ms/step - loss: 0.0063 - val_loss: 0.0409\n",
      "Epoch 22/30\n",
      "20/20 [==============================] - 7s 350ms/step - loss: 0.0062 - val_loss: 0.0410\n",
      "Epoch 23/30\n",
      "20/20 [==============================] - 8s 401ms/step - loss: 0.0061 - val_loss: 0.0411\n",
      "Epoch 24/30\n",
      "20/20 [==============================] - 9s 472ms/step - loss: 0.0060 - val_loss: 0.0415\n",
      "Epoch 25/30\n",
      "20/20 [==============================] - 9s 427ms/step - loss: 0.0060 - val_loss: 0.0418\n",
      "Epoch 26/30\n",
      "20/20 [==============================] - 7s 365ms/step - loss: 0.0059 - val_loss: 0.0421\n",
      "Epoch 27/30\n",
      "20/20 [==============================] - 7s 350ms/step - loss: 0.0058 - val_loss: 0.0424\n",
      "Epoch 28/30\n",
      "20/20 [==============================] - 10s 478ms/step - loss: 0.0057 - val_loss: 0.0431\n",
      "Epoch 29/30\n",
      "20/20 [==============================] - 8s 406ms/step - loss: 0.0056 - val_loss: 0.0443\n",
      "Epoch 30/30\n",
      " 5/20 [======>.......................] - ETA: 5s - loss: 0.0055"
     ]
    }
   ],
   "source": [
    "model_history = model.fit(x=x_train, y=y_train\n",
    "                          , epochs=EPOCHS\n",
    "                          , steps_per_epoch=EVALUATION_INTERVAL\n",
    "                          , validation_data=(x_val, y_val)\n",
    "                          , validation_steps=VALIDATION_INTERVAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & CV Error (curve by epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_history(history, title):\n",
    "    loss = history.history['loss'][1:]\n",
    "    val_loss = history.history['val_loss'][1:]\n",
    "    epochs = range(len(loss))\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_train_history(model_history, 'Multi-Step Training and validation loss')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "trainPredict = model.predict(x_train)\n",
    "cvPredict = model.predict(x_val)\n",
    "# invert predictions\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "cvPredict = scaler.inverse_transform(cvPredict)\n",
    "\n",
    "trainY = scaler.inverse_transform(y_train)\n",
    "cvY = scaler.inverse_transform(y_val)\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "if NUM_OF_FUTURE_PREDICTION == 1:\n",
    "    trainError = mean_absolute_percentage_error(trainPredict, trainY)\n",
    "    testError = mean_absolute_percentage_error(cvPredict, cvY)\n",
    "    layout = (1,2)\n",
    "    plt.figure(figsize=(17, 8))\n",
    "    plt.subplot2grid(layout, (0,0))\n",
    "    plt.plot(trainY, color='b', label='training data actual')\n",
    "    plt.plot(trainPredict , color='g', label='training data model')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.title('Mean Absolute Percentage Training Error: {0:.2f}%'.format(trainError))\n",
    "    plt.subplot2grid(layout, (0,1))\n",
    "    plt.plot(cvY, color='b', label='testing data actual')\n",
    "    plt.plot(cvPredict , color='r', label='testing data model')\n",
    "    plt.title('Mean Absolute Percentage Testing Error: {0:.2f}%'.format(testError))\n",
    "    plt.legend()\n",
    "    plt.grid(True);\n",
    "    plt.tight_layout()\n",
    "else:\n",
    "    trainError = mean_absolute_percentage_error(trainPredict[-1], trainY[-1])\n",
    "    testError = mean_absolute_percentage_error(cvPredict[-1], cvY[-1])\n",
    "    layout = (1,2)\n",
    "    plt.figure(figsize=(17, 8))\n",
    "    plt.subplot2grid(layout, (0,0))\n",
    "    plt.plot(trainY[-1], color='b', label='training data actual')\n",
    "    plt.plot(trainPredict[-1] , color='g', label='training data model')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.title('Mean Absolute Percentage Training Error: {0:.2f}%'.format(trainError))\n",
    "    plt.subplot2grid(layout, (0,1))\n",
    "    plt.plot(cvY[-1], color='b', label='testing data actual')\n",
    "    plt.plot(cvPredict[-1] , color='r', label='testing data model')\n",
    "    plt.title('Mean Absolute Percentage Testing Error: {0:.2f}%'.format(testError))\n",
    "    plt.legend()\n",
    "    plt.grid(True);\n",
    "    plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
